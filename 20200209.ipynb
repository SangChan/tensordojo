{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS = 10000\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data(num_words=NUM_WORDS)\n",
    "\n",
    "def multi_hot_sequences(sequences, dimension):\n",
    "    # 0으로 채워진 (len(sequences), dimension) 크기의 행렬을 만듭니다\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, word_indices in enumerate(sequences):\n",
    "        results[i, word_indices] = 1.0  # results[i]의 특정 인덱스만 1로 설정합니다\n",
    "    return results\n",
    "\n",
    "\n",
    "train_data = multi_hot_sequences(train_data, dimension=NUM_WORDS)\n",
    "test_data = multi_hot_sequences(test_data, dimension=NUM_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe36b989438>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                160016    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,305\n",
      "Trainable params: 160,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_model = keras.Sequential([\n",
    "    # `.summary` 메서드 때문에 `input_shape`가 필요합니다\n",
    "    keras.layers.Dense(16, activation='relu', input_shape=(NUM_WORDS,)),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "baseline_model.compile(optimizer='adam',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 - 54s - loss: 0.4999 - accuracy: 0.7994 - binary_crossentropy: 0.4999 - val_loss: 0.3535 - val_accuracy: 0.8738 - val_binary_crossentropy: 0.3535\n",
      "Epoch 2/20\n",
      "25000/25000 - 24s - loss: 0.2632 - accuracy: 0.9084 - binary_crossentropy: 0.2632 - val_loss: 0.2864 - val_accuracy: 0.8890 - val_binary_crossentropy: 0.2864\n",
      "Epoch 3/20\n",
      "25000/25000 - 17s - loss: 0.1927 - accuracy: 0.9322 - binary_crossentropy: 0.1927 - val_loss: 0.2847 - val_accuracy: 0.8865 - val_binary_crossentropy: 0.2847\n",
      "Epoch 4/20\n",
      "25000/25000 - 13s - loss: 0.1552 - accuracy: 0.9474 - binary_crossentropy: 0.1552 - val_loss: 0.3017 - val_accuracy: 0.8807 - val_binary_crossentropy: 0.3017\n",
      "Epoch 5/20\n",
      "25000/25000 - 18s - loss: 0.1290 - accuracy: 0.9574 - binary_crossentropy: 0.1290 - val_loss: 0.3261 - val_accuracy: 0.8758 - val_binary_crossentropy: 0.3261\n",
      "Epoch 6/20\n",
      "25000/25000 - 14s - loss: 0.1099 - accuracy: 0.9646 - binary_crossentropy: 0.1099 - val_loss: 0.3527 - val_accuracy: 0.8739 - val_binary_crossentropy: 0.3527\n",
      "Epoch 7/20\n",
      "25000/25000 - 13s - loss: 0.0930 - accuracy: 0.9707 - binary_crossentropy: 0.0930 - val_loss: 0.3844 - val_accuracy: 0.8697 - val_binary_crossentropy: 0.3844\n",
      "Epoch 8/20\n",
      "25000/25000 - 17s - loss: 0.0783 - accuracy: 0.9770 - binary_crossentropy: 0.0783 - val_loss: 0.4192 - val_accuracy: 0.8661 - val_binary_crossentropy: 0.4192\n",
      "Epoch 9/20\n",
      "25000/25000 - 15s - loss: 0.0672 - accuracy: 0.9822 - binary_crossentropy: 0.0672 - val_loss: 0.4590 - val_accuracy: 0.8616 - val_binary_crossentropy: 0.4590\n",
      "Epoch 10/20\n",
      "25000/25000 - 14s - loss: 0.0565 - accuracy: 0.9864 - binary_crossentropy: 0.0565 - val_loss: 0.4978 - val_accuracy: 0.8600 - val_binary_crossentropy: 0.4978\n",
      "Epoch 11/20\n",
      "25000/25000 - 15s - loss: 0.0476 - accuracy: 0.9898 - binary_crossentropy: 0.0476 - val_loss: 0.5422 - val_accuracy: 0.8565 - val_binary_crossentropy: 0.5422\n",
      "Epoch 12/20\n",
      "25000/25000 - 14s - loss: 0.0393 - accuracy: 0.9923 - binary_crossentropy: 0.0393 - val_loss: 0.5791 - val_accuracy: 0.8559 - val_binary_crossentropy: 0.5791\n",
      "Epoch 13/20\n",
      "25000/25000 - 18s - loss: 0.0332 - accuracy: 0.9943 - binary_crossentropy: 0.0332 - val_loss: 0.6212 - val_accuracy: 0.8537 - val_binary_crossentropy: 0.6212\n",
      "Epoch 14/20\n",
      "25000/25000 - 15s - loss: 0.0274 - accuracy: 0.9959 - binary_crossentropy: 0.0274 - val_loss: 0.6630 - val_accuracy: 0.8520 - val_binary_crossentropy: 0.6630\n",
      "Epoch 15/20\n",
      "25000/25000 - 16s - loss: 0.0224 - accuracy: 0.9970 - binary_crossentropy: 0.0224 - val_loss: 0.7049 - val_accuracy: 0.8507 - val_binary_crossentropy: 0.7049\n",
      "Epoch 16/20\n",
      "25000/25000 - 16s - loss: 0.0177 - accuracy: 0.9982 - binary_crossentropy: 0.0177 - val_loss: 0.7478 - val_accuracy: 0.8497 - val_binary_crossentropy: 0.7478\n",
      "Epoch 17/20\n",
      "25000/25000 - 15s - loss: 0.0142 - accuracy: 0.9990 - binary_crossentropy: 0.0142 - val_loss: 0.7855 - val_accuracy: 0.8495 - val_binary_crossentropy: 0.7855\n",
      "Epoch 18/20\n",
      "25000/25000 - 14s - loss: 0.0111 - accuracy: 0.9994 - binary_crossentropy: 0.0111 - val_loss: 0.8257 - val_accuracy: 0.8481 - val_binary_crossentropy: 0.8257\n",
      "Epoch 19/20\n",
      "25000/25000 - 13s - loss: 0.0085 - accuracy: 0.9998 - binary_crossentropy: 0.0085 - val_loss: 0.8601 - val_accuracy: 0.8477 - val_binary_crossentropy: 0.8601\n",
      "Epoch 20/20\n",
      "25000/25000 - 15s - loss: 0.0068 - accuracy: 0.9999 - binary_crossentropy: 0.0068 - val_loss: 0.8963 - val_accuracy: 0.8474 - val_binary_crossentropy: 0.8963\n"
     ]
    }
   ],
   "source": [
    "baseline_history = baseline_model.fit(train_data,\n",
    "                                      train_labels,\n",
    "                                      epochs=20,\n",
    "                                      batch_size=512,\n",
    "                                      validation_data=(test_data, test_labels),\n",
    "                                      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 4)                 40004     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 40,029\n",
      "Trainable params: 40,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "smaller_model = keras.Sequential([\n",
    "    keras.layers.Dense(4, activation='relu', input_shape=(NUM_WORDS,)),\n",
    "    keras.layers.Dense(4, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "smaller_model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "smaller_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 - 56s - loss: 0.5679 - accuracy: 0.7668 - binary_crossentropy: 0.5679 - val_loss: 0.4553 - val_accuracy: 0.8557 - val_binary_crossentropy: 0.4553\n",
      "Epoch 2/20\n",
      "25000/25000 - 8s - loss: 0.3660 - accuracy: 0.8888 - binary_crossentropy: 0.3660 - val_loss: 0.3506 - val_accuracy: 0.8793 - val_binary_crossentropy: 0.3506\n",
      "Epoch 3/20\n",
      "25000/25000 - 8s - loss: 0.2793 - accuracy: 0.9108 - binary_crossentropy: 0.2793 - val_loss: 0.3109 - val_accuracy: 0.8841 - val_binary_crossentropy: 0.3109\n",
      "Epoch 4/20\n",
      "25000/25000 - 32s - loss: 0.2323 - accuracy: 0.9251 - binary_crossentropy: 0.2323 - val_loss: 0.2920 - val_accuracy: 0.8881 - val_binary_crossentropy: 0.2920\n",
      "Epoch 5/20\n",
      "25000/25000 - 72s - loss: 0.2017 - accuracy: 0.9337 - binary_crossentropy: 0.2017 - val_loss: 0.2851 - val_accuracy: 0.8880 - val_binary_crossentropy: 0.2851\n",
      "Epoch 6/20\n",
      "25000/25000 - 24s - loss: 0.1787 - accuracy: 0.9411 - binary_crossentropy: 0.1787 - val_loss: 0.2847 - val_accuracy: 0.8874 - val_binary_crossentropy: 0.2847\n",
      "Epoch 7/20\n",
      "25000/25000 - 7s - loss: 0.1613 - accuracy: 0.9472 - binary_crossentropy: 0.1613 - val_loss: 0.2878 - val_accuracy: 0.8863 - val_binary_crossentropy: 0.2878\n",
      "Epoch 8/20\n",
      "25000/25000 - 8s - loss: 0.1463 - accuracy: 0.9538 - binary_crossentropy: 0.1463 - val_loss: 0.2937 - val_accuracy: 0.8831 - val_binary_crossentropy: 0.2937\n",
      "Epoch 9/20\n",
      "25000/25000 - 7s - loss: 0.1337 - accuracy: 0.9585 - binary_crossentropy: 0.1337 - val_loss: 0.3023 - val_accuracy: 0.8805 - val_binary_crossentropy: 0.3023\n",
      "Epoch 10/20\n",
      "25000/25000 - 8s - loss: 0.1233 - accuracy: 0.9622 - binary_crossentropy: 0.1233 - val_loss: 0.3149 - val_accuracy: 0.8775 - val_binary_crossentropy: 0.3149\n",
      "Epoch 11/20\n",
      "25000/25000 - 7s - loss: 0.1138 - accuracy: 0.9654 - binary_crossentropy: 0.1138 - val_loss: 0.3212 - val_accuracy: 0.8774 - val_binary_crossentropy: 0.3212\n",
      "Epoch 12/20\n",
      "25000/25000 - 8s - loss: 0.1049 - accuracy: 0.9692 - binary_crossentropy: 0.1049 - val_loss: 0.3345 - val_accuracy: 0.8739 - val_binary_crossentropy: 0.3345\n",
      "Epoch 13/20\n",
      "25000/25000 - 7s - loss: 0.0971 - accuracy: 0.9718 - binary_crossentropy: 0.0971 - val_loss: 0.3443 - val_accuracy: 0.8749 - val_binary_crossentropy: 0.3443\n",
      "Epoch 14/20\n",
      "25000/25000 - 8s - loss: 0.0897 - accuracy: 0.9752 - binary_crossentropy: 0.0897 - val_loss: 0.3589 - val_accuracy: 0.8716 - val_binary_crossentropy: 0.3589\n",
      "Epoch 15/20\n",
      "25000/25000 - 8s - loss: 0.0832 - accuracy: 0.9782 - binary_crossentropy: 0.0832 - val_loss: 0.3726 - val_accuracy: 0.8697 - val_binary_crossentropy: 0.3726\n",
      "Epoch 16/20\n",
      "25000/25000 - 8s - loss: 0.0774 - accuracy: 0.9809 - binary_crossentropy: 0.0774 - val_loss: 0.3865 - val_accuracy: 0.8683 - val_binary_crossentropy: 0.3865\n",
      "Epoch 17/20\n",
      "25000/25000 - 8s - loss: 0.0716 - accuracy: 0.9828 - binary_crossentropy: 0.0716 - val_loss: 0.4008 - val_accuracy: 0.8678 - val_binary_crossentropy: 0.4008\n",
      "Epoch 18/20\n",
      "25000/25000 - 8s - loss: 0.0668 - accuracy: 0.9842 - binary_crossentropy: 0.0668 - val_loss: 0.4180 - val_accuracy: 0.8644 - val_binary_crossentropy: 0.4180\n",
      "Epoch 19/20\n"
     ]
    }
   ],
   "source": [
    "smaller_history = smaller_model.fit(train_data,\n",
    "                                    train_labels,\n",
    "                                    epochs=20,\n",
    "                                    batch_size=512,\n",
    "                                    validation_data=(test_data, test_labels),\n",
    "                                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(NUM_WORDS,)),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "bigger_model.compile(optimizer='adam',\n",
    "                     loss='binary_crossentropy',\n",
    "                     metrics=['accuracy','binary_crossentropy'])\n",
    "\n",
    "bigger_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_history = bigger_model.fit(train_data, train_labels,\n",
    "                                  epochs=20,\n",
    "                                  batch_size=512,\n",
    "                                  validation_data=(test_data, test_labels),\n",
    "                                  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(histories, key='binary_crossentropy'):\n",
    "  plt.figure(figsize=(16,10))\n",
    "\n",
    "  for name, history in histories:\n",
    "    val = plt.plot(history.epoch, history.history['val_'+key],\n",
    "                   '--', label=name.title()+' Val')\n",
    "    plt.plot(history.epoch, history.history[key], color=val[0].get_color(),\n",
    "             label=name.title()+' Train')\n",
    "\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel(key.replace('_',' ').title())\n",
    "  plt.legend()\n",
    "\n",
    "  plt.xlim([0,max(history.epoch)])\n",
    "\n",
    "\n",
    "plot_history([('baseline', baseline_history),\n",
    "              ('smaller', smaller_history),\n",
    "              ('bigger', bigger_history)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "                       activation='relu', input_shape=(NUM_WORDS,)),\n",
    "    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "                       activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "l2_model.compile(optimizer='adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "l2_model_history = l2_model.fit(train_data, train_labels,\n",
    "                                epochs=20,\n",
    "                                batch_size=512,\n",
    "                                validation_data=(test_data, test_labels),\n",
    "                                verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([('baseline', baseline_history),\n",
    "              ('l2', l2_model_history)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpt_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(16, activation='relu', input_shape=(NUM_WORDS,)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "dpt_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy','binary_crossentropy'])\n",
    "\n",
    "dpt_model_history = dpt_model.fit(train_data, train_labels,\n",
    "                                  epochs=20,\n",
    "                                  batch_size=512,\n",
    "                                  validation_data=(test_data, test_labels),\n",
    "                                  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([('baseline', baseline_history),\n",
    "              ('dropout', dpt_model_history)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
