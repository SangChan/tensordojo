{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 SimpleRNN 레이어 생성 코드\n",
    "rnn1 = tf.keras.layers.SimpleRNN(units=1, activation='tanh', return_sequences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. ]\n",
      " [0.1]\n",
      " [0.2]\n",
      " [0.3]] 0.4\n",
      "[[0.1]\n",
      " [0.2]\n",
      " [0.3]\n",
      " [0.4]] 0.5\n",
      "[[0.2]\n",
      " [0.3]\n",
      " [0.4]\n",
      " [0.5]] 0.6\n",
      "[[0.3]\n",
      " [0.4]\n",
      " [0.5]\n",
      " [0.6]] 0.7\n",
      "[[0.4]\n",
      " [0.5]\n",
      " [0.6]\n",
      " [0.7]] 0.8\n",
      "[[0.5]\n",
      " [0.6]\n",
      " [0.7]\n",
      " [0.8]] 0.9\n"
     ]
    }
   ],
   "source": [
    "# 7.2 시퀀스 예측 데이터 생성\n",
    "X = []\n",
    "Y = []\n",
    "for i in range(6):\n",
    "    # [0,1,2,3], [1,2,3,4] 같은 정수의 시퀀스를 만듭니다.\n",
    "    lst = list(range(i,i+4))\n",
    "\n",
    "    # 위에서 구한 시퀀스의 숫자들을 각각 10으로 나눈 다음 저장합니다.\n",
    "    # SimpleRNN 에 각 타임스텝에 하나씩 숫자가 들어가기 때문에 여기서도 하나씩 분리해서 배열에 저장합니다.\n",
    "    X.append(list(map(lambda c: [c/10], lst)))\n",
    "\n",
    "    # 정답에 해당하는 4, 5 등의 정수를 역시 위처럼 10으로 나눠서 저장합니다.\n",
    "    Y.append((i+4)/10)\n",
    "    \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "for i in range(len(X)):\n",
    "    print(X[i], Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 7.3 시퀀스 예측 모델 정의\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units=10, return_sequences=False, input_shape=[4,1]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3495787 ]\n",
      " [0.5264076 ]\n",
      " [0.65786314]\n",
      " [0.74338144]\n",
      " [0.788827  ]\n",
      " [0.8022073 ]]\n"
     ]
    }
   ],
   "source": [
    "# 7.4 네트워크 훈련 및 결과 확인\n",
    "model.fit(X, Y, epochs=100, verbose=0)\n",
    "print(model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7912071]]\n",
      "[[0.13882202]]\n"
     ]
    }
   ],
   "source": [
    "# 7.5 학습되지 않은 시퀀스에 대한 예측 결과\n",
    "print(model.predict(np.array([[[0.6],[0.7],[0.8],[0.9]]])))\n",
    "print(model.predict(np.array([[[-0.1],[0.0],[0.1],[0.2]]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46567689]\n",
      " [0.         0.84158534]\n",
      " [0.         0.69936495]\n",
      " [0.         0.24653426]\n",
      " [0.         0.66962343]\n",
      " [0.         0.83667793]\n",
      " [0.         0.34365394]\n",
      " [0.         0.09529412]\n",
      " [0.         0.21820448]\n",
      " [0.         0.81843304]\n",
      " [0.         0.65574531]\n",
      " [0.         0.07641501]\n",
      " [0.         0.78145247]\n",
      " [0.         0.66000605]\n",
      " [0.         0.99245126]\n",
      " [0.         0.88901471]\n",
      " [0.         0.42037093]\n",
      " [0.         0.6358847 ]\n",
      " [0.         0.80034558]\n",
      " [0.         0.6620595 ]\n",
      " [0.         0.36448852]\n",
      " [0.         0.0146234 ]\n",
      " [0.         0.89012541]\n",
      " [0.         0.24552949]\n",
      " [0.         0.79616374]\n",
      " [0.         0.36033974]\n",
      " [0.         0.39802097]\n",
      " [0.         0.60450572]\n",
      " [0.         0.53244548]\n",
      " [0.         0.39785162]\n",
      " [0.         0.56928637]\n",
      " [0.         0.15156371]\n",
      " [0.         0.16779198]\n",
      " [0.         0.88984759]\n",
      " [0.         0.42102233]\n",
      " [0.         0.91127513]\n",
      " [0.         0.47919177]\n",
      " [0.         0.18959286]\n",
      " [0.         0.9806504 ]\n",
      " [0.         0.70155338]\n",
      " [0.         0.99190264]\n",
      " [0.         0.08647897]\n",
      " [0.         0.89521865]\n",
      " [0.         0.87873083]\n",
      " [0.         0.45039662]\n",
      " [0.         0.06726034]\n",
      " [0.         0.11506618]\n",
      " [0.         0.47307308]\n",
      " [0.         0.06432409]\n",
      " [0.         0.44087193]\n",
      " [0.         0.71177259]\n",
      " [0.         0.32940641]\n",
      " [0.         0.01935823]\n",
      " [0.         0.01998311]\n",
      " [0.         0.31873359]\n",
      " [0.         0.55199613]\n",
      " [0.         0.0791386 ]\n",
      " [0.         0.83471274]\n",
      " [0.         0.04788976]\n",
      " [0.         0.59869546]\n",
      " [0.         0.87416253]\n",
      " [0.         0.75013533]\n",
      " [0.         0.76697509]\n",
      " [0.         0.46113443]\n",
      " [0.         0.7656576 ]\n",
      " [0.         0.38574123]\n",
      " [0.         0.92465335]\n",
      " [0.         0.05454146]\n",
      " [0.         0.78361325]\n",
      " [0.         0.48166334]\n",
      " [0.         0.33264399]\n",
      " [0.         0.25986187]\n",
      " [0.         0.82318782]\n",
      " [0.         0.67416647]\n",
      " [1.         0.957155  ]\n",
      " [0.         0.11564927]\n",
      " [0.         0.4519217 ]\n",
      " [0.         0.98283362]\n",
      " [0.         0.85733727]\n",
      " [0.         0.42884856]\n",
      " [0.         0.5230333 ]\n",
      " [0.         0.7141237 ]\n",
      " [1.         0.17356448]\n",
      " [0.         0.30573826]\n",
      " [0.         0.35113362]\n",
      " [0.         0.82957178]\n",
      " [0.         0.73547616]\n",
      " [0.         0.02474997]\n",
      " [0.         0.67026204]\n",
      " [0.         0.62815963]\n",
      " [0.         0.97809841]\n",
      " [0.         0.49256207]\n",
      " [0.         0.16707958]\n",
      " [0.         0.19269694]\n",
      " [0.         0.36202581]\n",
      " [0.         0.05701993]\n",
      " [0.         0.28601885]\n",
      " [0.         0.30816588]\n",
      " [0.         0.12259621]\n",
      " [0.         0.97973095]] 0.16612811030245386\n"
     ]
    }
   ],
   "source": [
    "# 7.6 곱셈 문제 데이터 생성\n",
    "X = []\n",
    "Y = []\n",
    "for i in range(3000):\n",
    "    # 0~1 사이의 랜덤한 숫자 100 개를 만듭니다.\n",
    "    lst = np.random.rand(100)\n",
    "    # 마킹할 숫자 2개의 인덱스를 뽑습니다.\n",
    "    idx = np.random.choice(100, 2, replace=False)\n",
    "    # 마킹 인덱스가 저장된 원-핫 인코딩 벡터를 만듭니다.\n",
    "    zeros = np.zeros(100)\n",
    "    zeros[idx] = 1\n",
    "    # 마킹 인덱스와 랜덤한 숫자를 합쳐서 X 에 저장합니다.\n",
    "    X.append(np.array(list(zip(zeros, lst))))\n",
    "    # 마킹 인덱스가 1인 값들만 서로 곱해서 Y 에 저장합니다.\n",
    "    Y.append(np.prod(lst[idx]))\n",
    "    \n",
    "print(X[0], Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 100, 30)           990       \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 2,851\n",
      "Trainable params: 2,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 7.7 SimpleRNN 레이어를 사용한 곱셈 문제 모델 정의\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units=30, return_sequences=True, input_shape=[100,2]),\n",
    "    tf.keras.layers.SimpleRNN(units=30),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2048 samples, validate on 512 samples\n",
      "Epoch 1/100\n",
      "2048/2048 [==============================] - 10s 5ms/sample - loss: 0.0701 - val_loss: 0.0508\n",
      "Epoch 2/100\n",
      "2048/2048 [==============================] - 5s 3ms/sample - loss: 0.0488 - val_loss: 0.0496\n",
      "Epoch 3/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0469 - val_loss: 0.0493\n",
      "Epoch 4/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0512 - val_loss: 0.0487\n",
      "Epoch 5/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0473 - val_loss: 0.0486\n",
      "Epoch 6/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0479 - val_loss: 0.0487\n",
      "Epoch 7/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0475 - val_loss: 0.0485\n",
      "Epoch 8/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0470 - val_loss: 0.0511\n",
      "Epoch 9/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0485 - val_loss: 0.0521\n",
      "Epoch 10/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0475 - val_loss: 0.0483\n",
      "Epoch 11/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0465 - val_loss: 0.0482\n",
      "Epoch 12/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0473 - val_loss: 0.0485\n",
      "Epoch 13/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0470 - val_loss: 0.0486\n",
      "Epoch 14/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0465 - val_loss: 0.0486\n",
      "Epoch 15/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0468 - val_loss: 0.0487\n",
      "Epoch 16/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0463 - val_loss: 0.0493\n",
      "Epoch 17/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0459 - val_loss: 0.0490\n",
      "Epoch 18/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0466 - val_loss: 0.0486\n",
      "Epoch 19/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0462 - val_loss: 0.0499\n",
      "Epoch 20/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0461 - val_loss: 0.0482\n",
      "Epoch 21/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0459 - val_loss: 0.0494\n",
      "Epoch 22/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0459 - val_loss: 0.0494\n",
      "Epoch 23/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0457 - val_loss: 0.0512\n",
      "Epoch 24/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0457 - val_loss: 0.0489\n",
      "Epoch 25/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0461 - val_loss: 0.0486\n",
      "Epoch 26/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0460 - val_loss: 0.0485\n",
      "Epoch 27/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0459 - val_loss: 0.0497\n",
      "Epoch 28/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0454 - val_loss: 0.0488\n",
      "Epoch 29/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0454 - val_loss: 0.0498\n",
      "Epoch 30/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0453 - val_loss: 0.0503\n",
      "Epoch 31/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0445 - val_loss: 0.0499\n",
      "Epoch 32/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0450 - val_loss: 0.0515\n",
      "Epoch 33/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0445 - val_loss: 0.0542\n",
      "Epoch 34/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0443 - val_loss: 0.0494\n",
      "Epoch 35/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0455 - val_loss: 0.0558\n",
      "Epoch 36/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0445 - val_loss: 0.0506\n",
      "Epoch 37/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0444 - val_loss: 0.0515\n",
      "Epoch 38/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0440 - val_loss: 0.0518\n",
      "Epoch 39/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0438 - val_loss: 0.0551\n",
      "Epoch 40/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0440 - val_loss: 0.0533\n",
      "Epoch 41/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0429 - val_loss: 0.0536\n",
      "Epoch 42/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0432 - val_loss: 0.0524\n",
      "Epoch 43/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0440 - val_loss: 0.0532\n",
      "Epoch 44/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0432 - val_loss: 0.0614\n",
      "Epoch 45/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0439 - val_loss: 0.0535\n",
      "Epoch 46/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0432 - val_loss: 0.0527\n",
      "Epoch 47/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0433 - val_loss: 0.0540\n",
      "Epoch 48/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0423 - val_loss: 0.0587\n",
      "Epoch 49/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0423 - val_loss: 0.0543\n",
      "Epoch 50/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0427 - val_loss: 0.0533\n",
      "Epoch 51/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0420 - val_loss: 0.0554\n",
      "Epoch 52/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0418 - val_loss: 0.0564\n",
      "Epoch 53/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0412 - val_loss: 0.0556\n",
      "Epoch 54/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0412 - val_loss: 0.0538\n",
      "Epoch 55/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0413 - val_loss: 0.0603\n",
      "Epoch 56/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0414 - val_loss: 0.0540\n",
      "Epoch 57/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0415 - val_loss: 0.0599\n",
      "Epoch 58/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0407 - val_loss: 0.0531\n",
      "Epoch 59/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0399 - val_loss: 0.0567\n",
      "Epoch 60/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0404 - val_loss: 0.0548\n",
      "Epoch 61/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0393 - val_loss: 0.0576\n",
      "Epoch 62/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0394 - val_loss: 0.0537\n",
      "Epoch 63/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0385 - val_loss: 0.0548\n",
      "Epoch 64/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0384 - val_loss: 0.0573\n",
      "Epoch 65/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0377 - val_loss: 0.0558\n",
      "Epoch 66/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0381 - val_loss: 0.0572\n",
      "Epoch 67/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0383 - val_loss: 0.0593\n",
      "Epoch 68/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0393 - val_loss: 0.0564\n",
      "Epoch 69/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0380 - val_loss: 0.0617\n",
      "Epoch 70/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0373 - val_loss: 0.0583\n",
      "Epoch 71/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0363 - val_loss: 0.0595\n",
      "Epoch 72/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0372 - val_loss: 0.0578\n",
      "Epoch 73/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0365 - val_loss: 0.0551\n",
      "Epoch 74/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0362 - val_loss: 0.0578\n",
      "Epoch 75/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0365 - val_loss: 0.0583\n",
      "Epoch 76/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0353 - val_loss: 0.0591\n",
      "Epoch 77/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0356 - val_loss: 0.0600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0352 - val_loss: 0.0594\n",
      "Epoch 79/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0354 - val_loss: 0.0577\n",
      "Epoch 80/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0342 - val_loss: 0.0619\n",
      "Epoch 81/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0346 - val_loss: 0.0600\n",
      "Epoch 82/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0343 - val_loss: 0.0647\n",
      "Epoch 83/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0345 - val_loss: 0.0597\n",
      "Epoch 84/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0332 - val_loss: 0.0605\n",
      "Epoch 85/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0328 - val_loss: 0.0618\n",
      "Epoch 86/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0331 - val_loss: 0.0632\n",
      "Epoch 87/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0339 - val_loss: 0.0635\n",
      "Epoch 88/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0330 - val_loss: 0.0578\n",
      "Epoch 89/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0323 - val_loss: 0.0597\n",
      "Epoch 90/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0331 - val_loss: 0.0633\n",
      "Epoch 91/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0323 - val_loss: 0.0685\n",
      "Epoch 92/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0323 - val_loss: 0.0627\n",
      "Epoch 93/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0314 - val_loss: 0.0624\n",
      "Epoch 94/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0313 - val_loss: 0.0640\n",
      "Epoch 95/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0305 - val_loss: 0.0646\n",
      "Epoch 96/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0306 - val_loss: 0.0644\n",
      "Epoch 97/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0314 - val_loss: 0.0612\n",
      "Epoch 98/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0294 - val_loss: 0.0677\n",
      "Epoch 99/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0298 - val_loss: 0.0671\n",
      "Epoch 100/100\n",
      "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0295 - val_loss: 0.0677\n"
     ]
    }
   ],
   "source": [
    "# 7.8 SimpleRNN 네트워크 학습\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "# 2560개의 데이터만 학습시킵니다. validation 데이터는 20% 로 지정합니다.\n",
    "history = model.fit(X[:2560], Y[:2560], epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
